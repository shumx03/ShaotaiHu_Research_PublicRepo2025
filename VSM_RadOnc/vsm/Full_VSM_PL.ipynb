{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160e2ac8-1c35-4a42-a839-ecd3726f73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "W2V VSM Full Pipeline\n",
    "Testing pipeline that generates vector embeddings & cosine similarities for radiation oncology clinical practice documents \n",
    "Created on Thursday Apr 5 19:17:45 2025\n",
    "@authors: Samuel luk, Shaotai Hu\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a87abc-5c8b-40bc-927c-7a2791cdb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### packages & custom functions ###\n",
    "import os, random, re, math, pandas as pd, numpy as np, matplotlib.pyplot as plt, gensim, warnings\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sim_functions_final import cos_sim, eud_dis, man_dis\n",
    "from vsm_functions_final import shuffle, build_corpus, tokenize, w2v_train, bal_ran_subsamp, total_words, vector_append, vector_gen, skl_tfidf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483806c-41db-4228-9fe2-cabf129ee702",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data ###\n",
    "output_dir = \"###\"\n",
    "path_1 = \"###\"\n",
    "path_2 = \"###\"\n",
    "data1_f = pd.read_csv(path_1)\n",
    "data2_f = pd.read_csv(path_2)\n",
    "data1_f[\"column\"] = data1_f[\"column\"].str.replace(\" \", \"-\", regex=False)\n",
    "data2_f[\"column\"] = data2_f[\"column\"].str.replace(\" \", \"-\", regex=False)\n",
    "temp_full_data = pd.concat([data1_f, data2_f], ignore_index=True)\n",
    "column_subjects = list(temp_full_data[\"column\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35087178",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing weight & aggregation functions ###\n",
    "# Takes tokenized corpus\n",
    "def count_term(data, node, term):\n",
    "    count = 0\n",
    "    for t in data[node]:\n",
    "        if t == term:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "# aggregated cos_similarity for a subject in column\n",
    "def aggregate_loc(data, w2v_results):\n",
    "    N = len(data)\n",
    "    weighted_nodes = {}\n",
    "    for node in nodes_in[1:len(nodes_in)]:\n",
    "        #print(node)\n",
    "        data[node] = data[node].astype(str)\n",
    "        weights = {}\n",
    "        for e in data[node].unique():\n",
    "            e_count = count_term(data, node, e)\n",
    "            weights[e] = e_count / N\n",
    "        #print(np.sum(list(weights.values())))\n",
    "        temp = 0\n",
    "        for key in weights:\n",
    "            #print(f\"{key}: {weights[key]}, {key}: {w2v_results[key]}\")\n",
    "            temp += weights[key] * w2v_results[key]\n",
    "        weighted_nodes[node] = temp\n",
    "    final_cs = np.sum(list(weighted_nodes.values()))/len(nodes_in[1:len(nodes_in)])\n",
    "    return final_cs, weighted_nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### all_loc pipeline ###\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "# 0 is model loc cs and 1 is weighted cs\n",
    "weighted_df = pd.DataFrame(columns = column_subjects, index = [0, 1])\n",
    "\n",
    "for subject in column_subjects:\n",
    "\n",
    "    data1 = data1_f[data1_f[\"column\"] == subject] \n",
    "    data2 = data2_f[data2_f[\"column\"] == subject] \n",
    "    \n",
    "    # used in weight calculation\n",
    "    all_data = pd.concat([data1, data2], ignore_index=True)\n",
    "    all_lower = all_data.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    all_lower[\"subject1\"] = \"###_\" + all_lower[\"subject1\"].astype(str)\n",
    "    #...\n",
    "\n",
    "    toks1 = tokenize(build_corpus(data1, nodes_in))\n",
    "    toks2 = tokenize(build_corpus(data2, nodes_in))\n",
    "    toks_base12 = toks1+toks2\n",
    "    \n",
    "    w2v_mall = Word2Vec(workers = 1, seed = 12345, min_count = 1000, vector_size = 1000)\n",
    "    w2v_corall = w2v_train(w2v_mall, toks_base12) \n",
    "    cbw_results = {}\n",
    "    eud_results = {}\n",
    "    man_results = {}\n",
    "\n",
    "    for i in w2v_corall.wv.index_to_key:\n",
    "        cbw_results[i] = []\n",
    "        eud_results[i] = []\n",
    "        man_results[i] = []\n",
    "\n",
    "    for i in range(10):\n",
    "        # hyperparameters are randomized for confidentiality\n",
    "        w2v_m1 = Word2Vec(workers = 1000,\n",
    "                    seed = 12345,\n",
    "                    vector_size = 1000,\n",
    "                    window = 1000,\n",
    "                    min_count = 1000,\n",
    "                    epochs = 1000,\n",
    "                    sg = 0,\n",
    "                    cbow_mean = 1)\n",
    "    \n",
    "        w2v_m2 = Word2Vec(workers = 1000,\n",
    "                    seed = 12345,\n",
    "                    vector_size = 1000,\n",
    "                    window = 1000,\n",
    "                    min_count = 1000,\n",
    "                    epochs = 1000,\n",
    "                    sg = 0,\n",
    "                    cbow_mean = 1)\n",
    "\n",
    "        #to account for known w2v output randomness\n",
    "        w2v_cor1 = w2v_train(w2v_m1, shuffle(toks1)) \n",
    "        w2v_cor2 = w2v_train(w2v_m2, shuffle(toks2)) \n",
    "\n",
    "        mutual_ts = set(w2v_cor1.wv.index_to_key) & set(w2v_cor2.wv.index_to_key)\n",
    "        # stores the iterations of cos_sim models\n",
    "        for i in w2v_corall.wv.index_to_key:\n",
    "            if i in mutual_ts:\n",
    "                cbw_results[i].append(cos_sim(w2v_cor1.wv[i], w2v_cor2.wv[i]))\n",
    "                eud_results[i].append(eud_dis(w2v_cor1.wv[i], w2v_cor2.wv[i]))\n",
    "                man_results[i].append(man_dis(w2v_cor1.wv[i], w2v_cor2.wv[i]))\n",
    "            else:\n",
    "                cbw_results[i].append(0)\n",
    "                eud_results[i].append(0)\n",
    "                man_results[i].append(0)\n",
    "                \n",
    "    ### weights ###\n",
    "    mean_results = {key: np.mean(value) for key, value in cbw_results.items()}\n",
    "    #print(mean_results)\n",
    "    #eud_mean = {key: np.mean(value) for key, value in eud_results.items()}\n",
    "    #man_mean = {key: np.mean(value) for key, value in man_results.items()}\n",
    "    \n",
    "    single_cs = np.round(float(mean_results[subject.lower()]), 4)\n",
    "    weighted_cs = np.round(aggregate_loc(all_lower, mean_results)[0], 4)\n",
    "    \n",
    "    weighted_df[subject] = [single_cs, weighted_cs]\n",
    "    \n",
    "    # rename the subject loc column to cbw_loc to represent the single w2v value  \n",
    "    cbw_results[\"cbw_loc\"] = cbw_results.pop(subject.lower())\n",
    "    \n",
    "    # turns into df and adds the subject loc in every row\n",
    "    cbwdf = pd.DataFrame(cbw_results)\n",
    "    cbwdf.insert(0, \"subject\", f\"{subject}\")\n",
    "    \n",
    "    # appends to overall df\n",
    "    df_all = pd.concat([df_all, cbwdf], ignore_index = True)\n",
    "    \n",
    "    # moves the index of cbw_loc to 1\n",
    "    cols = df_all.columns.tolist()\n",
    "    cols.insert(1, cols.pop(cols.index(\"cbw_loc\")))\n",
    "    df_final = df_all[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdcb5cbf-dce6-40e9-9615-2556eaf5e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test distribution saving as csv ###\n",
    "test_df = df_final.round(6)\n",
    "output_folder = os.path.join(output_dir, \"distribution.csv\") # update\n",
    "test_df.to_csv(output_folder, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a25affc-13e8-4807-8a8b-12cc42c58246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>eud_dis</th>\n",
       "      <th>man_dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF</th>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.3829</td>\n",
       "      <td>1.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_TF-IDF</th>\n",
       "      <td>0.8441</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>2.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w2v</th>\n",
       "      <td>0.899321</td>\n",
       "      <td>0.445571</td>\n",
       "      <td>4.389835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cos_sim   eud_dis   man_dis\n",
       "TF                0.9267    0.3829     1.704\n",
       "sklearn_TF-IDF    0.8441    0.5585     2.893\n",
       "w2v             0.899321  0.445571  4.389835"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Result Summary Table with TF and TF-IDF ###\n",
    "\n",
    "vsms = [\"TF\", \"sklearn_TF-IDF\", \"w2v\"]\n",
    "sim_funcs = [\"cos_sim\", \"eud_dis\", \"man_dis\"]\n",
    "\n",
    "df = pd.DataFrame(index = vsms, columns = sim_funcs) \n",
    "\n",
    "df[\"cos_sim\"][\"TF\"] = np.round((cos_sim(vector_gen(data1, data2, nodes_in)[0], vector_gen(data1, data2, nodes_in)[1])), 4)\n",
    "df[\"eud_dis\"][\"TF\"] = np.round((eud_dis(vector_gen(data1, data2, nodes_in)[0], vector_gen(data1, data2, nodes_in)[1])), 4)\n",
    "df[\"man_dis\"][\"TF\"] = np.round((man_dis(vector_gen(data1, data2, nodes_in)[0], vector_gen(data1, data2, nodes_in)[1])), 4)\n",
    "\n",
    "df[\"cos_sim\"][\"sklearn_TF-IDF\"] = np.round(cos_sim(skl_tfidf(corpora, corpus1)[0], skl_tfidf(corpora, corpus1)[1]), 4)\n",
    "df[\"eud_dis\"][\"sklearn_TF-IDF\"] = np.round(eud_dis(skl_tfidf(corpora, corpus1)[0], skl_tfidf(corpora, corpus1)[1]), 4)\n",
    "df[\"man_dis\"][\"sklearn_TF-IDF\"] = np.round(man_dis(skl_tfidf(corpora, corpus1)[0], skl_tfidf(corpora, corpus1)[1]), 4)\n",
    "\n",
    "df[\"cos_sim\"][\"w2v\"] = mean_results[\"subject\"]\n",
    "df[\"eud_dis\"][\"w2v\"] = eud_mean[\"subject\"]\n",
    "df[\"man_dis\"][\"w2v\"] = man_mean[\"subject\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cd8ee-bb9e-4125-882d-92d4217b858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dictionary plotting functions ###\n",
    "def plotting_dict_line(dict):\n",
    "    fig, axes = plt.subplots(len(dict), 1, figsize=(10, len(dict) * 5))\n",
    "    for i, (key, values) in enumerate(dict.items()):\n",
    "        axes[i].plot(values, marker='o', linestyle='-', color='purple')  \n",
    "        axes[i].set_title(f\"subject cos_sims at {key} words in corpus\")\n",
    "        axes[i].set_xlabel(\"permutation count\")\n",
    "        axes[i].set_ylabel(\"cos_sims\")\n",
    "        axes[i].axhline(0, color='black',linewidth=1)  \n",
    "        axes[i].axvline(0, color='black',linewidth=1) \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plotting_dict_bar(dict):\n",
    "    fig, axes = plt.subplots(len(dict), 1, figsize=(10, len(dict) * 5))\n",
    "    for i, (key, values) in enumerate(dict.items()):\n",
    "        axes[i].bar(range(len(values)), values, color='black')  \n",
    "        axes[i].set_title(f\"cos_sims values at permutation count: {key}\")\n",
    "        axes[i].set_xlabel(\"index\")\n",
    "        axes[i].set_ylabel(\"cos_sim\")\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#plotting_dict_line(cos_sims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
