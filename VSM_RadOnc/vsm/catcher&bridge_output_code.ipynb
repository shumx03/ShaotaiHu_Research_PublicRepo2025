{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2f496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VSM Output Catcher & Reconstruction Code\n",
    "Created on Tuesday May 20 21:33:14 2025\n",
    "@authors: Samuel luk, Shaotai Hu\n",
    "For data reconstruction & processing and analysis of packaged_final_w2v (differential privacy applied) outputs\n",
    "\"\"\";\n",
    " \n",
    "import os, random, re, math, pickle, pandas as pd, numpy as np, matplotlib.pyplot as plt, gensim, warnings\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sim_functions_final import cos_sim, eud_dis, man_dis\n",
    "from vsm_functions_final import shuffle, build_corpus, tokenize, w2v_train, bal_ran_subsamp, total_words, vector_append, vector_gen, skl_tfidf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334acc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Cossim catcher & Bridge code ###\n",
    "\n",
    "# takes pandas dataframes saved as pickle files \n",
    "output_catch1 = \"###.pkl\"\n",
    "with open(output_catch1, \"rb\") as f:\n",
    "    loaded_df1 = pickle.load(f)\n",
    "    \n",
    "output_catch2 = \"###.pkl\"\n",
    "with open(output_catch2, \"rb\") as f2:\n",
    "    loaded_df2 = pickle.load(f2)\n",
    "\n",
    "# processing & reconstruction of cosine similarities using dataframes of vector embeddings \n",
    "mutual_cols = np.sort(list(set(list(loaded_df1.columns)) & set(list(loaded_df2.columns))))\n",
    "df1_new = loaded_df1[mutual_cols]\n",
    "df2_new = loaded_df2[mutual_cols]\n",
    "\n",
    "final_df = pd.DataFrame(columns=df1_new.columns, index=df1_new.index)\n",
    "for r in range(0, len(final_df.index)):\n",
    "    for c in range(0, len(final_df.columns)):\n",
    "        if isinstance(df1_new.iloc[r, c], np.ndarray) and isinstance(df2_new.iloc[r, c], np.ndarray):\n",
    "            final_df.iloc[r, c] = cos_sim(df1_new.iloc[r, c], df2_new.iloc[r, c])\n",
    "        elif isinstance(df1_new.iloc[r, c], str):\n",
    "            final_df.iloc[r, c] = df1_new.iloc[r, c]\n",
    "        else:\n",
    "            final_df.iloc[r, c] = np.nan\n",
    "\n",
    "subject_col = final_df.pop(\"subject\")  \n",
    "final_df.insert(0, \"subject\", subject_col)\n",
    "all_subjects = final_df[\"subject\"].unique()\n",
    "\n",
    "# grouping per location\n",
    "grouped = {subject: group_df for subject, group_df in final_df.groupby(\"subject\")}\n",
    "loc_dfs = [grouped[loc] for loc in final_df[\"subject\"].unique()]\n",
    "all_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs = []\n",
    "for df in loc_dfs:\n",
    "    subject = df[\"subject\"].iloc[0].lower()\n",
    "    temp_df = df.rename(columns={\"cbw_loc\": subject})\n",
    "    temp_df = temp_df.drop(columns=[\"subject\"])\n",
    "    cols = temp_df.columns.tolist() \n",
    "    cols[0], cols[1] = cols[1], cols[0]  \n",
    "    temp_df = temp_df[cols]\n",
    "    final_dfs.append(temp_df)\n",
    "\n",
    "# final_dfs is a list of all the dataframes contained the calculated cossims\n",
    "final_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04eb33ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breast': 0.7245,\n",
       " 'central-nervous-system-(cns)': 0.8671,\n",
       " 'gastrointestinal-(gi)': 0.8619,\n",
       " 'genitourinary-(gu)': 0.8462,\n",
       " 'gynecologic-(gyn)': 0.8994,\n",
       " 'head-and-neck': 0.7748,\n",
       " 'hem-lymph': 0.6693,\n",
       " 'lung': 0.9001,\n",
       " 'metastasis': 0.7385,\n",
       " 'musculoskeletal': 0.2091,\n",
       " 'other': 0.8312,\n",
       " 'sarcoma': 0.6295,\n",
       " 'skin': 0.2363,\n",
       " 'thoracic': 0.0205}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights catcher & Bridge code\n",
    "# Note, the dfs in the list of dfs final_dfs \n",
    "# are in the same order as subjects in all_subjects, so the weighting is matched correctly through indexing\n",
    "output_weight1 = \"###.pkl\"\n",
    "with open(output_weight1, 'rb') as w1:\n",
    "    loaded_weights1 = pickle.load(w1)\n",
    "    \n",
    "output_weight2 = \"###.pkl\"\n",
    "with open(output_weight2, 'rb') as w2:\n",
    "    loaded_weights2 = pickle.load(w2)\n",
    "\n",
    "# Transforming weights dictionary pickle file to weights and applying to cosine similarities from above\n",
    "def sum_nested_dicts(dict1, dict2):\n",
    "    result = {}\n",
    "    for subject in dict1:\n",
    "        if subject in dict2:\n",
    "            if isinstance(dict1[subject], dict) and isinstance(dict2[subject], dict):\n",
    "                result[subject] = sum_nested_dicts(dict1[subject], dict2[subject])\n",
    "            else:\n",
    "                result[subject] = dict1[subject] + dict2[subject]\n",
    "        else:\n",
    "            result[subject] = dict1[subject]\n",
    "    for subject in dict2:\n",
    "        if subject not in dict1:\n",
    "            result[subject] = dict2[subject]\n",
    "    return result\n",
    "\n",
    "all_weights = sum_nested_dicts(loaded_weights1, loaded_weights2)\n",
    "\n",
    "# Applies the weights to every subject in final_dfs to generate weighted cos_sims\n",
    "weighted_per_loc = {}\n",
    "for i in range(len(all_subjects)):\n",
    "    subject = all_subjects[i]\n",
    "    mean_cbw = final_dfs[i].mean().to_dict()\n",
    "    mean_cbw = {key: 0.0 if math.isnan(value) else value for key, value in mean_cbw.items()}\n",
    "    weighted_nodes = {}\n",
    "    for node in nodes_in:\n",
    "        weighted = []\n",
    "        for e in all_weights[subject][node].keys():\n",
    "            if e in mean_cbw.keys():\n",
    "                w = all_weights[subject][node][e] / all_weights[subject][\"total_per_node\"] * mean_cbw[e]\n",
    "                weighted.append(w)\n",
    "            weighted_nodes[node] = np.sum(weighted)\n",
    "    weighted_per_loc[subject] = np.round(np.mean(list(weighted_nodes.values())), 4)\n",
    "weighted_per_loc = {key.lower(): value for key, value in weighted_per_loc.items()}\n",
    "weighted_per_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b427980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breast': 0.784,\n",
       " 'central-nervous-system-(cns)': 0.9059,\n",
       " 'gastrointestinal-(gi)': 0.8942,\n",
       " 'genitourinary-(gu)': 0.887,\n",
       " 'gynecologic-(gyn)': 0.9285,\n",
       " 'head-and-neck': 0.9002,\n",
       " 'hem-lymph': 0.8475,\n",
       " 'lung': 0.9351,\n",
       " 'metastasis': 0.7485,\n",
       " 'musculoskeletal': 0.4981,\n",
       " 'other': 0.9116,\n",
       " 'sarcoma': 0.8844,\n",
       " 'skin': 0.5439,\n",
       " 'thoracic': 0.0214}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_per_loc = {}\n",
    "for i in range(len(all_subjects)):\n",
    "    subject = all_subjects[i].lower()\n",
    "    if i != 10:\n",
    "        mean_cbw = final_dfs[i].mean().to_dict()\n",
    "        mean_cbw = {key: 0.0 if math.isnan(value) else value for key, value in mean_cbw.items()}\n",
    "        model_per_loc[subject] = np.round(mean_cbw[subject], 4)\n",
    "    else: \n",
    "        model_per_loc[subject] = np.round(np.mean(final_dfs[i].iloc[:, 0]), 4)\n",
    "model_per_loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
